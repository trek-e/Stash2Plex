---
phase: 20-graduated-recovery-rate-limiting
plan: 02
type: execute
wave: 2
depends_on: ["20-01"]
files_modified:
  - worker/processor.py
  - worker/recovery.py
  - tests/worker/test_processor.py
  - tests/worker/test_recovery.py
  - tests/test_main.py
autonomous: true

must_haves:
  truths:
    - "Worker loop enforces rate limiting during recovery period (jobs wait before processing)"
    - "Circuit HALF_OPEN->CLOSED transition triggers recovery period start in rate limiter"
    - "Job success/failure during recovery feeds into error rate monitoring"
    - "Recovery period state (recovery_started_at) persists to recovery_state.json across restarts"
    - "Normal operation (circuit CLOSED, no recovery period) has zero overhead from rate limiter"
  artifacts:
    - path: "worker/processor.py"
      provides: "Rate limiter integration in _worker_loop"
      contains: "rate_limiter"
    - path: "worker/recovery.py"
      provides: "Extended RecoveryState with recovery_started_at for rate limiter"
      contains: "recovery_started_at"
  key_links:
    - from: "worker/processor.py"
      to: "worker/rate_limiter.py"
      via: "self._rate_limiter.should_wait() check in _worker_loop"
      pattern: "_rate_limiter\\.should_wait"
    - from: "worker/processor.py"
      to: "worker/rate_limiter.py"
      via: "self._rate_limiter.record_result() after job completes"
      pattern: "_rate_limiter\\.record_result"
    - from: "worker/processor.py"
      to: "worker/rate_limiter.py"
      via: "start_recovery_period() when circuit transitions HALF_OPEN->CLOSED"
      pattern: "start_recovery_period"
    - from: "worker/recovery.py"
      to: "recovery_state.json"
      via: "recovery_started_at persisted for cross-restart continuity"
      pattern: "recovery_started_at"
---

<objective>
Wire RecoveryRateLimiter into the worker loop and extend recovery state persistence for cross-restart recovery period continuity.

Purpose: The rate limiter from Plan 01 needs to be called from the worker loop to actually enforce rate limiting during recovery. Recovery period state must persist so plugin restarts don't reset the graduated ramp.

Output: Modified worker/processor.py with rate limiting, extended recovery state persistence
</objective>

<execution_context>
@/Users/trekkie/.claude/get-shit-done/workflows/execute-plan.md
@/Users/trekkie/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/20-graduated-recovery-rate-limiting/20-RESEARCH.md
@.planning/phases/20-graduated-recovery-rate-limiting/20-01-SUMMARY.md
@worker/processor.py
@worker/recovery.py
@worker/rate_limiter.py
@worker/circuit_breaker.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Extend RecoveryState and wire rate limiter into SyncWorker</name>
  <files>worker/recovery.py, worker/processor.py</files>
  <action>
**Step 1: Extend RecoveryState in `worker/recovery.py`:**

Add `recovery_started_at` field to RecoveryState dataclass (default 0.0). This field tracks when the current recovery period began, enabling cross-restart continuity of the graduated ramp.

```python
@dataclass
class RecoveryState:
    last_check_time: float = 0.0
    consecutive_successes: int = 0
    consecutive_failures: int = 0
    last_recovery_time: float = 0.0
    recovery_count: int = 0
    recovery_started_at: float = 0.0  # NEW: when recovery period began (0.0 = not in recovery)
```

Modify `RecoveryScheduler.record_health_check()`: When recovery is detected (circuit transitions to CLOSED), set `state.recovery_started_at = time.time()` and save. This is the trigger for the rate limiter.

Add a helper method `clear_recovery_period(self)` that loads state, sets `recovery_started_at = 0.0`, and saves. Called when recovery period ends.

**Step 2: Wire RecoveryRateLimiter into SyncWorker.__init__ in `worker/processor.py`:**

In `__init__`, after circuit breaker initialization:

```python
# Recovery rate limiter for graduated queue drain
from worker.rate_limiter import RecoveryRateLimiter
self._rate_limiter = RecoveryRateLimiter()

# Check if recovery period is active from prior session (cross-restart continuity)
if data_dir is not None:
    from worker.recovery import RecoveryScheduler
    recovery_scheduler = RecoveryScheduler(data_dir)
    recovery_state = recovery_scheduler.load_state()
    if recovery_state.recovery_started_at > 0:
        # Recovery period was active before restart — resume from current position
        self._rate_limiter.start_recovery_period(now=recovery_state.recovery_started_at)
        log_info("Resuming recovery rate limiting from prior session")
```

**Step 3: Add rate limiting check in `_worker_loop` in `worker/processor.py`:**

After the circuit breaker check (line ~306, after `if not self.circuit_breaker.can_execute()` block) and BEFORE `item = get_pending(...)`, add:

```python
# Rate limit during recovery period (graduated queue drain)
wait_time = self._rate_limiter.should_wait()
if wait_time > 0:
    _dbg and log_info(f"[DEBUG] Recovery rate limit: waiting {wait_time:.2f}s (rate={self._rate_limiter.current_rate():.1f}/s)")
    # Sleep in small chunks so stop() can interrupt quickly
    remaining = wait_time
    while remaining > 0 and self.running:
        chunk = min(remaining, 0.5)
        time.sleep(chunk)
        remaining -= chunk
    continue
```

**Step 4: Detect circuit recovery and start rate limiter in `_worker_loop`:**

After `self.circuit_breaker.record_success()` (line ~379), detect HALF_OPEN->CLOSED transition:

```python
# Success: acknowledge job and record with circuit breaker
previous_state = self.circuit_breaker.state
ack_job(self.queue, item)
self.circuit_breaker.record_success()

# Detect recovery: HALF_OPEN -> CLOSED transition starts recovery period
if previous_state == CircuitState.HALF_OPEN and self.circuit_breaker.state == CircuitState.CLOSED:
    self._rate_limiter.start_recovery_period()
    # Persist recovery_started_at for cross-restart continuity
    if self.data_dir is not None:
        from worker.recovery import RecoveryScheduler
        scheduler = RecoveryScheduler(self.data_dir)
        state = scheduler.load_state()
        state.recovery_started_at = time.time()
        scheduler.save_state(state)
    log_info("Recovery period started: graduated rate limiting enabled")
```

**Step 5: Record job results with rate limiter for error monitoring:**

After successful job processing (near line ~382, after `self._stats.record_success()`):
```python
self._rate_limiter.record_result(success=True)
```

After TransientError handling (in the except block):
```python
self._rate_limiter.record_result(success=False)
```

After PlexServerDown handling:
```python
self._rate_limiter.record_result(success=False)
```

**Step 6: Clean up recovery period when ramp completes:**

In the `_worker_loop`, after the rate limit check, add cleanup when recovery period ends naturally:

```python
# Check if recovery period ended (ramp complete)
if self._rate_limiter.is_in_recovery_period() is False and hasattr(self, '_was_in_recovery') and self._was_in_recovery:
    self._was_in_recovery = False
    if self.data_dir is not None:
        from worker.recovery import RecoveryScheduler
        scheduler = RecoveryScheduler(self.data_dir)
        scheduler.clear_recovery_period()
    log_info("Recovery period complete: normal processing speed resumed")
```

Actually, simpler approach: track `_was_in_recovery` as a flag. Set it when `start_recovery_period()` is called. On each loop iteration, check if recovery period ended (should_wait returns 0.0 and is_in_recovery_period is False). When transition detected, clear persisted state.

Add `self._was_in_recovery = False` to `__init__` (after rate limiter init). Set to `True` when starting recovery period. Check for transition in the loop.

**IMPORTANT considerations from research:**
- Sleep in small chunks (0.5s) so `stop()` can interrupt quickly
- Recovery period detection: capture circuit state BEFORE record_success() to detect transition
- Error recording: record after EVERY job outcome (success, transient error, server down)
- Cross-restart: load recovery_started_at from recovery_state.json on init, pass as `now` to start_recovery_period
- Do NOT record results for PermanentError (these are data problems, not Plex health)
  </action>
  <verify>
`pytest tests/worker/test_processor.py -v` — existing tests pass (no regressions)
`pytest tests/worker/test_recovery.py -v` — existing tests pass (new field has default, backward compatible)
`pytest --tb=short` — full suite passes
  </verify>
  <done>
- SyncWorker._rate_limiter initialized in __init__
- _worker_loop checks should_wait() before processing each job
- HALF_OPEN->CLOSED transition starts recovery period
- Job results recorded for error rate monitoring
- Recovery period state persists via recovery_state.json
- Cross-restart: rate limiter resumes from persisted recovery_started_at
- All existing tests pass (backward compatible)
  </done>
</task>

<task type="auto">
  <name>Task 2: Integration tests for rate limiting in worker loop</name>
  <files>tests/worker/test_processor.py, tests/worker/test_recovery.py, tests/test_main.py</files>
  <action>
**Add tests to `tests/worker/test_processor.py`** for rate limiter integration (8-12 new tests):

1. **Rate limiter initialized:** Verify SyncWorker has `_rate_limiter` attribute after init.

2. **No rate limiting in normal operation:** When circuit is CLOSED and no recovery period active, jobs process without delay. Verify `should_wait()` returns 0.0. (Use mock time or verify no sleep called for rate limiting.)

3. **Rate limiting during recovery:** Mock `_rate_limiter.should_wait()` to return >0 value. Verify worker loop sleeps in 0.5s chunks and continues (doesn't process job during wait).

4. **Recovery period starts on HALF_OPEN->CLOSED transition:** Set circuit breaker to HALF_OPEN state. Process a job that succeeds. Verify `_rate_limiter.start_recovery_period()` was called.

5. **Job success records result:** Process a job successfully. Verify `_rate_limiter.record_result(success=True)` was called.

6. **TransientError records failure result:** Process a job that raises TransientError. Verify `_rate_limiter.record_result(success=False)` was called.

7. **PlexServerDown records failure result:** Process a job that raises PlexServerDown. Verify `_rate_limiter.record_result(success=False)` was called.

8. **Cross-restart resume:** Create SyncWorker with data_dir containing recovery_state.json with recovery_started_at set to recent timestamp. Verify rate limiter starts in recovery period.

9. **Recovery period cleanup:** When is_in_recovery_period transitions from True to False, verify recovery_started_at is cleared in persisted state.

10. **Stop interrupts rate limit wait:** Start worker, mock should_wait to return long wait time, call stop(). Verify worker stops promptly (within ~1s).

**Add tests to `tests/worker/test_recovery.py`** (3-4 new tests):

1. **RecoveryState has recovery_started_at field:** Default is 0.0.
2. **recovery_started_at persists to JSON:** Save state with recovery_started_at=1234.5, load it back, verify value.
3. **record_health_check sets recovery_started_at on recovery:** When circuit transitions HALF_OPEN->CLOSED, verify state.recovery_started_at is set.
4. **clear_recovery_period resets recovery_started_at:** Call method, verify state has recovery_started_at=0.0.

**Test patterns to follow:**
- Use existing test fixtures from test_processor.py (mock_stash_gql, worker fixtures)
- Mock the rate_limiter methods to control behavior without real timing
- Use `unittest.mock.patch` for time-dependent behavior
- Ensure metadata quality gate is satisfied in mock data (tests need meaningful metadata)
  </action>
  <verify>
`pytest tests/worker/test_processor.py -v` — all tests pass (existing + new)
`pytest tests/worker/test_recovery.py -v` — all tests pass (existing + new)
`pytest --tb=short` — full suite passes, no regressions
`pytest --cov=worker --cov-report=term-missing` — coverage maintained or improved
  </verify>
  <done>
- 8-12 new integration tests for rate limiter in processor
- 3-4 new tests for extended recovery state
- All existing tests pass (backward compatible changes)
- Coverage maintained above 80% threshold
- Full test suite passes (1086+ tests)
  </done>
</task>

</tasks>

<verification>
- `pytest --tb=short` — full suite passes (1086+ tests, no regressions)
- `pytest --cov=worker --cov-report=term-missing` — coverage >= 80%
- Manual trace through code path: circuit OPEN -> recovery health check succeeds -> HALF_OPEN -> job succeeds -> CLOSED -> start_recovery_period() -> should_wait() returns delay -> jobs rate-limited -> ramp completes -> normal speed
</verification>

<success_criteria>
- Worker loop enforces rate limiting during recovery period
- HALF_OPEN->CLOSED transition triggers recovery period
- Job results feed error rate monitoring
- Recovery period persists across plugin restarts
- Normal operation has zero rate limiting overhead
- All tests pass, no regressions
</success_criteria>

<output>
After completion, create `.planning/phases/20-graduated-recovery-rate-limiting/20-02-SUMMARY.md`
</output>
