---
phase: 08-observability-improvements
plan: 01
type: execute
wave: 1
depends_on: []
files_modified:
  - worker/stats.py
  - sync_queue/dlq.py
  - tests/unit/worker/test_stats.py
  - tests/unit/sync_queue/test_dlq.py
autonomous: true

must_haves:
  truths:
    - "Stats dataclass tracks success/failure counts"
    - "Stats dataclass tracks timing metrics"
    - "Stats dataclass tracks match confidence counts"
    - "DLQ provides error type breakdown"
    - "Stats can be persisted to and loaded from JSON file"
  artifacts:
    - path: "worker/stats.py"
      provides: "SyncStats dataclass with tracking methods"
      exports: ["SyncStats"]
    - path: "sync_queue/dlq.py"
      provides: "Error aggregation method"
      contains: "get_error_summary"
  key_links:
    - from: "worker/stats.py"
      to: "stats.json"
      via: "save_to_file/load_from_file methods"
      pattern: "json\\.(dump|load)"
    - from: "sync_queue/dlq.py"
      to: "dead_letters table"
      via: "GROUP BY error_type query"
      pattern: "GROUP BY error_type"
---

<objective>
Create the statistics tracking infrastructure for observability improvements.

Purpose: Enable tracking of sync operation metrics (success/fail counts, timing, match confidence) and DLQ error type aggregation - the foundation for batch summary logging.

Output:
- `worker/stats.py` with SyncStats dataclass
- Enhanced `sync_queue/dlq.py` with `get_error_summary()` method
- Unit tests for both
</objective>

<execution_context>
@/Users/trekkie/.claude/get-shit-done/workflows/execute-plan.md
@/Users/trekkie/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/08-observability-improvements/08-RESEARCH.md

# Existing code to extend
@worker/processor.py
@sync_queue/dlq.py
@plex/timing.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create SyncStats dataclass with persistence</name>
  <files>worker/stats.py, tests/unit/worker/test_stats.py</files>
  <action>
Create `worker/stats.py` with a SyncStats dataclass following the pattern from RESEARCH.md:

**SyncStats dataclass fields:**
- `jobs_processed: int = 0`
- `jobs_succeeded: int = 0`
- `jobs_failed: int = 0`
- `jobs_to_dlq: int = 0`
- `total_processing_time: float = 0.0`
- `session_start: float = field(default_factory=time.time)`
- `errors_by_type: Dict[str, int] = field(default_factory=dict)`
- `high_confidence_matches: int = 0`
- `low_confidence_matches: int = 0`

**Methods to implement:**
- `record_success(processing_time: float, confidence: str = 'high')` - Increment success counters, add timing, track confidence
- `record_failure(error_type: str, processing_time: float, to_dlq: bool = False)` - Increment failure counters, track error type
- `success_rate` property - Return percentage (0 if no jobs processed)
- `avg_processing_time` property - Return average time per job (0 if no jobs)
- `to_dict()` - Return dict representation for JSON serialization
- `save_to_file(filepath: str)` - Save stats to JSON file with cumulative merge
- `load_from_file(filepath: str)` classmethod - Load stats from JSON file, return new instance

**Persistence strategy:**
- On save: Load existing file, merge cumulative totals, write back
- On load: Return new SyncStats with cumulative totals from file
- Handle missing file gracefully (return empty stats)

**Create tests in `tests/unit/worker/test_stats.py`:**
- Test record_success increments counters correctly
- Test record_success tracks confidence (high/low)
- Test record_failure increments counters and tracks error type
- Test record_failure with to_dlq=True increments dlq counter
- Test success_rate calculation (including 0 jobs edge case)
- Test avg_processing_time calculation (including 0 jobs edge case)
- Test to_dict returns all fields
- Test save_to_file creates JSON file
- Test load_from_file returns stats from file
- Test load_from_file with missing file returns empty stats
- Test save merges with existing file (cumulative totals)
  </action>
  <verify>
Run: `pytest tests/unit/worker/test_stats.py -v`
All tests pass. File `worker/stats.py` exists with SyncStats class.
  </verify>
  <done>
SyncStats dataclass tracks: jobs_processed, jobs_succeeded, jobs_failed, jobs_to_dlq, timing, errors_by_type, high/low confidence matches. Can save/load from JSON file.
  </done>
</task>

<task type="auto">
  <name>Task 2: Add get_error_summary to DLQ</name>
  <files>sync_queue/dlq.py, tests/unit/sync_queue/test_dlq.py</files>
  <action>
Add `get_error_summary()` method to `DeadLetterQueue` class in `sync_queue/dlq.py`:

```python
def get_error_summary(self) -> dict[str, int]:
    """
    Get count of DLQ entries grouped by error type.

    Returns:
        Dict mapping error_type to count, e.g., {"PlexNotFound": 3, "PermanentError": 2}
    """
    with self._get_connection() as conn:
        cursor = conn.execute(
            'SELECT error_type, COUNT(*) as count FROM dead_letters GROUP BY error_type'
        )
        return {row[0]: row[1] for row in cursor.fetchall()}
```

**Add tests to existing `tests/unit/sync_queue/test_dlq.py`:**
- Test get_error_summary returns empty dict for empty DLQ
- Test get_error_summary returns correct counts by error type
- Test get_error_summary with multiple entries of same type
- Test get_error_summary with multiple different error types

Use the existing test patterns in the file - the file already has fixtures for DLQ testing.
  </action>
  <verify>
Run: `pytest tests/unit/sync_queue/test_dlq.py -v -k error_summary`
New tests pass. Method exists in dlq.py.
  </verify>
  <done>
DLQ has `get_error_summary()` method that returns `{"PlexNotFound": 3, "PermanentError": 2}` style breakdown from database.
  </done>
</task>

</tasks>

<verification>
1. `pytest tests/unit/worker/test_stats.py -v` - All stats tests pass
2. `pytest tests/unit/sync_queue/test_dlq.py -v -k error_summary` - DLQ tests pass
3. `python -c "from worker.stats import SyncStats; print(SyncStats())"` - Import works
4. `python -c "from sync_queue.dlq import DeadLetterQueue; print(hasattr(DeadLetterQueue, 'get_error_summary'))"` - Returns True
</verification>

<success_criteria>
- SyncStats dataclass exists with all tracking methods
- Stats can be saved to and loaded from JSON file
- DLQ.get_error_summary() returns error type counts from database
- All unit tests pass
</success_criteria>

<output>
After completion, create `.planning/phases/08-observability-improvements/08-01-SUMMARY.md`
</output>
