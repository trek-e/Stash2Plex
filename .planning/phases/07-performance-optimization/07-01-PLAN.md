---
phase: 07-performance-optimization
plan: 01
type: execute
wave: 1
depends_on: []
files_modified:
  - requirements.txt
  - plex/cache.py
autonomous: true

must_haves:
  truths:
    - "Cache persists to disk and survives restarts"
    - "Library data is cached with TTL expiration"
    - "Cache hit returns data without Plex API call"
  artifacts:
    - path: "plex/cache.py"
      provides: "PlexCache class with disk-backed caching"
      min_lines: 100
    - path: "requirements.txt"
      provides: "diskcache dependency"
      contains: "diskcache"
  key_links:
    - from: "plex/cache.py"
      to: "diskcache.Cache"
      via: "import and instantiation"
      pattern: "from diskcache import Cache"
---

<objective>
Create disk-backed caching infrastructure using diskcache library for Plex library data.

Purpose: Establish the caching foundation that will reduce Plex API calls by storing library data (search results, all() results) on disk with TTL-based expiration.

Output: plex/cache.py module with PlexCache class providing disk-based caching with 1-hour TTL for library data.
</objective>

<execution_context>
@/Users/trekkie/.claude/get-shit-done/workflows/execute-plan.md
@/Users/trekkie/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/07-performance-optimization/07-RESEARCH.md

# Existing modules to understand patterns
@plex/client.py
@plex/matcher.py
@sync_queue/operations.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Add diskcache dependency</name>
  <files>requirements.txt</files>
  <action>
Add diskcache>=5.6.0 to requirements.txt. This library provides SQLite-backed disk caching with:
- Thread-safe and process-safe operations
- TTL support via expire parameter
- Memoization decorators
- Statistics tracking

Add it after the existing dependencies, maintaining alphabetical order is not required.
  </action>
  <verify>Run `pip install -r requirements.txt` and verify diskcache installs successfully</verify>
  <done>diskcache>=5.6.0 appears in requirements.txt and can be imported</done>
</task>

<task type="auto">
  <name>Task 2: Create cache infrastructure module</name>
  <files>plex/cache.py</files>
  <action>
Create plex/cache.py with PlexCache class providing disk-backed caching for Plex library data.

Implementation requirements:
1. Use diskcache.Cache for SQLite-backed storage
2. Store cache in data_dir/cache/ directory (follows existing pattern from sync_queue)
3. Library data TTL: 3600 seconds (1 hour) per RESEARCH.md recommendation
4. Cache size limit: 100MB (configurable) to prevent unbounded growth
5. Store only essential data (keys, titles, file paths) NOT full plexapi objects (avoids memory bloat per RESEARCH.md pitfall #3)

Class structure:
```python
class PlexCache:
    """Disk-backed cache for Plex library data."""

    def __init__(self, data_dir: str, library_ttl: int = 3600, size_limit: int = 100*1024*1024):
        """Initialize cache in data_dir/cache/ directory."""

    def get_library_items(self, library_name: str) -> Optional[List[dict]]:
        """Get cached library items (simplified dicts, not plexapi objects)."""

    def set_library_items(self, library_name: str, items: List) -> None:
        """Cache library items, extracting only essential fields."""

    def get_search_results(self, library_name: str, title: str) -> Optional[List[dict]]:
        """Get cached search results."""

    def set_search_results(self, library_name: str, title: str, results: List) -> None:
        """Cache search results."""

    def clear(self) -> None:
        """Clear all cached data."""

    def get_stats(self) -> dict:
        """Get cache hit/miss statistics."""
```

For items, extract only: key, title, and file paths (from media[].parts[].file). This is sufficient for matching and avoids pickling full plexapi objects.

Add helper function `_extract_item_data(item)` to safely extract essential fields from plexapi Video objects.

Use logging pattern from other plex modules (logger = logging.getLogger('PlexSync.plex.cache')).
  </action>
  <verify>
Run Python to verify module imports:
```python
from plex.cache import PlexCache
import tempfile
cache = PlexCache(tempfile.mkdtemp())
print("Cache initialized:", cache)
```
  </verify>
  <done>plex/cache.py exists with PlexCache class that can be instantiated and stores data to disk</done>
</task>

<task type="auto">
  <name>Task 3: Add unit tests for cache module</name>
  <files>tests/test_cache.py</files>
  <action>
Create tests/test_cache.py with tests covering:

1. Cache initialization creates directory
2. Library items get/set with TTL
3. Search results get/set with TTL
4. Cache miss returns None
5. Cache clear removes all data
6. Statistics tracking (hits/misses)
7. Item data extraction preserves essential fields

Use tmp_path fixture for isolated test directories (same pattern as test_queue.py).

Test that cached data survives PlexCache re-instantiation (persistence test).

Do NOT test actual plexapi integration - mock the input items with dict-like objects having the expected attributes (media, parts, file, key, title).
  </action>
  <verify>Run `pytest tests/test_cache.py -v` and all tests pass</verify>
  <done>tests/test_cache.py has 7+ tests covering cache operations, all passing</done>
</task>

</tasks>

<verification>
1. `pip install -r requirements.txt` succeeds
2. `python -c "from plex.cache import PlexCache; print('OK')"` succeeds
3. `pytest tests/test_cache.py -v` all tests pass
4. Cache data persists in SQLite file (check data_dir/cache/ after test)
</verification>

<success_criteria>
- diskcache dependency added and installable
- PlexCache class provides disk-backed caching with TTL
- Cache stores simplified item data (not full plexapi objects)
- Unit tests verify cache operations including persistence
</success_criteria>

<output>
After completion, create `.planning/phases/07-performance-optimization/07-01-SUMMARY.md`
</output>
