---
phase: 09-reliability-hardening
plan: 02
type: execute
wave: 2
depends_on: ["09-01"]
files_modified:
  - worker/processor.py
  - validation/errors.py
  - tests/worker/test_processor.py
  - tests/integration/test_reliability.py
autonomous: true

must_haves:
  truths:
    - "Single field update failure does not fail entire sync job"
    - "Partial success is logged with aggregated warnings"
    - "Critical field failures (title/path) still fail the job"
    - "API response validation catches malformed Plex responses"
  artifacts:
    - path: "worker/processor.py"
      provides: "Granular per-field error handling"
      contains: "PartialSyncResult"
    - path: "validation/errors.py"
      provides: "Field update warning aggregation"
      contains: "FieldUpdateWarning"
    - path: "tests/worker/test_processor.py"
      provides: "Tests for partial failure recovery"
      contains: "test_partial"
    - path: "tests/integration/test_reliability.py"
      provides: "Integration tests for partial sync"
      contains: "TestPartialFailure"
  key_links:
    - from: "worker/processor.py"
      to: "validation/errors.py"
      via: "FieldUpdateWarning import"
      pattern: "from validation.errors import"
    - from: "worker/processor.py"
      to: "log output"
      via: "warning aggregation"
      pattern: "log_warn.*partial.*warnings"
---

<objective>
Implement partial failure recovery with granular per-field error handling and API response validation for Phase 9 reliability hardening.

Purpose: Ensure that a single field update failure (e.g., performer sync fails) doesn't cause the entire metadata sync to fail. Title and path updates can still succeed. Aggregate warnings for visibility without job failure.

Output: Updated processor.py with granular error handling, FieldUpdateWarning class, comprehensive tests for partial sync scenarios.
</objective>

<execution_context>
@/Users/trekkie/.claude/get-shit-done/workflows/execute-plan.md
@/Users/trekkie/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/09-reliability-hardening/09-RESEARCH.md
@worker/processor.py
@validation/errors.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Add FieldUpdateWarning and PartialSyncResult classes</name>
  <files>
    - validation/errors.py (modify)
    - tests/validation/test_errors.py (modify)
  </files>
  <action>
Update `validation/errors.py` to add classes for partial sync tracking:

```python
from dataclasses import dataclass, field
from typing import List, Optional

@dataclass
class FieldUpdateWarning:
    """
    Warning for a non-critical field update that failed.

    These are logged but don't fail the entire sync job.
    Examples: performer sync failed, tag sync failed, poster upload failed.
    """
    field_name: str           # e.g., "performers", "tags", "poster"
    error_message: str        # The exception message
    error_type: str           # The exception class name

    def __str__(self) -> str:
        return f"{self.field_name}: {self.error_message}"


@dataclass
class PartialSyncResult:
    """
    Result of a metadata sync that may have partial failures.

    Tracks which fields succeeded, which had warnings, and provides
    a summary for logging.
    """
    success: bool = True                              # Overall success (critical fields OK)
    warnings: List[FieldUpdateWarning] = field(default_factory=list)
    fields_updated: List[str] = field(default_factory=list)

    def add_warning(self, field_name: str, error: Exception) -> None:
        """Add a warning for a non-critical field failure."""
        self.warnings.append(FieldUpdateWarning(
            field_name=field_name,
            error_message=str(error),
            error_type=type(error).__name__
        ))

    def add_success(self, field_name: str) -> None:
        """Record a successful field update."""
        self.fields_updated.append(field_name)

    @property
    def has_warnings(self) -> bool:
        return len(self.warnings) > 0

    @property
    def warning_summary(self) -> str:
        """Human-readable summary of warnings."""
        if not self.warnings:
            return ""
        return f"{len(self.warnings)} warnings: " + "; ".join(str(w) for w in self.warnings)
```

Update `tests/validation/test_errors.py`:
- Test FieldUpdateWarning creation and string representation
- Test PartialSyncResult add_warning and add_success
- Test warning_summary formatting
- Test has_warnings property
  </action>
  <verify>
```bash
pytest tests/validation/test_errors.py -v --no-cov
python3 -c "from validation.errors import FieldUpdateWarning, PartialSyncResult; print('Import OK')"
```
  </verify>
  <done>
- FieldUpdateWarning dataclass exists with field_name, error_message, error_type
- PartialSyncResult dataclass exists with warning aggregation
- All tests pass
  </done>
</task>

<task type="auto">
  <name>Task 2: Implement granular error handling in _update_metadata</name>
  <files>
    - worker/processor.py (modify)
    - tests/worker/test_processor.py (modify)
  </files>
  <action>
Refactor `worker/processor.py` `_update_metadata()` to use granular per-field error handling:

1. Import PartialSyncResult from validation.errors

2. Create PartialSyncResult at start of _update_metadata()

3. Wrap each field group in try-except:

**Critical fields (fail job if these fail):**
- title (required)
- path matching (already handled in _process_job)

**Non-critical fields (warn but continue):**
- studio
- summary/details
- tagline
- date
- performers (actor sync)
- tags (genre sync)
- poster upload
- background upload
- collection add

Example structure:
```python
def _update_metadata(self, plex_item, data: dict) -> PartialSyncResult:
    """Update Plex item metadata with granular error handling."""
    from validation.errors import PartialSyncResult

    result = PartialSyncResult()
    edits = {}

    # Critical: title update (if present, failure = job failure)
    # ... existing title logic, no try-except needed, let it propagate

    # Non-critical: studio update
    try:
        if 'studio' in data:
            # ... existing studio logic from Task 1 of 09-01
            result.add_success('studio')
    except Exception as e:
        result.add_warning('studio', e)

    # Non-critical: summary/details
    try:
        # ... existing summary logic
        result.add_success('summary')
    except Exception as e:
        result.add_warning('summary', e)

    # Apply scalar edits
    if edits:
        try:
            plex_item.edit(**edits)
            plex_item.reload()
        except Exception as e:
            # If basic edit fails, that's a real failure
            raise

    # Non-critical: performers (separate edit call)
    try:
        # ... existing performer logic
        result.add_success('performers')
    except Exception as e:
        result.add_warning('performers', e)

    # Non-critical: tags
    try:
        # ... existing tag logic
        result.add_success('tags')
    except Exception as e:
        result.add_warning('tags', e)

    # Non-critical: poster
    try:
        # ... existing poster logic
        result.add_success('poster')
    except Exception as e:
        result.add_warning('poster', e)

    # Non-critical: background
    try:
        # ... existing background logic
        result.add_success('background')
    except Exception as e:
        result.add_warning('background', e)

    # Non-critical: collection
    try:
        # ... existing collection logic
        result.add_success('collection')
    except Exception as e:
        result.add_warning('collection', e)

    # Log warnings if any
    if result.has_warnings:
        log_warn(f"Partial sync for {plex_item.title}: {result.warning_summary}")

    return result
```

4. Update _process_job to receive and handle PartialSyncResult:
- Log at INFO level for successful partial sync
- Track partial success in stats (count as success with note)

Update `tests/worker/test_processor.py`:
- Add test: performer sync fails, title sync succeeds, job succeeds
- Add test: tag sync fails, other fields succeed, job succeeds
- Add test: poster upload fails, metadata sync succeeds, job succeeds
- Add test: multiple non-critical failures aggregated in warning
- Add test: title field failure still fails job (critical field)
  </action>
  <verify>
```bash
pytest tests/worker/test_processor.py -v -k "partial" --no-cov
pytest tests/worker/test_processor.py -v --no-cov
```
  </verify>
  <done>
- _update_metadata returns PartialSyncResult
- Non-critical field failures are caught and added to warnings
- Critical field failures (title) still propagate
- Warnings are logged at WARN level
- All tests pass
  </done>
</task>

<task type="auto">
  <name>Task 3: Add response validation and integration tests</name>
  <files>
    - worker/processor.py (modify)
    - tests/integration/test_reliability.py (modify)
  </files>
  <action>
Add response validation to critical Plex operations in `worker/processor.py`:

1. After `plex_item.edit(**edits)` and `plex_item.reload()`:
   - Verify reload succeeded (item still exists)
   - Log if edit seemed to succeed but values didn't update (potential silent failure)

2. Add validation helper:
```python
def _validate_edit_result(self, plex_item, expected_edits: dict) -> list[str]:
    """
    Validate that edit actually applied expected values.

    Returns list of fields that may not have updated correctly.
    This catches silent failures where Plex accepts the request
    but doesn't apply the value (e.g., field limit exceeded).
    """
    issues = []
    for field_key, expected_value in expected_edits.items():
        # Parse field name from "field.value" format
        field_name = field_key.replace('.value', '').replace('.locked', '')
        actual_value = getattr(plex_item, field_name, None)

        # Check if value matches (with some tolerance for sanitization)
        if expected_value and actual_value:
            if str(expected_value)[:50] != str(actual_value)[:50]:
                issues.append(f"{field_name}: sent '{expected_value[:20]}...', got '{actual_value[:20]}...'")
        elif expected_value and not actual_value:
            issues.append(f"{field_name}: sent value but field is empty")

    return issues
```

3. Call validation after successful edit, log any issues as debug (not warning, since edit "succeeded")

Update `tests/integration/test_reliability.py`:
- Add TestPartialFailure class with:
  - test_performer_failure_doesnt_fail_job
  - test_poster_upload_failure_doesnt_fail_job
  - test_multiple_field_failures_aggregated
  - test_title_failure_fails_job
- Add TestResponseValidation class with:
  - test_silent_truncation_detected
  - test_edit_validation_logs_issues
  </action>
  <verify>
```bash
pytest tests/integration/test_reliability.py -v --no-cov
pytest tests/ -v --no-cov -x  # Full test suite, stop on first failure
```
  </verify>
  <done>
- Response validation helper added to processor
- Integration tests cover partial failure scenarios
- Full test suite passes
- No regressions
  </done>
</task>

</tasks>

<verification>
```bash
# All tests pass
pytest tests/validation/test_errors.py tests/worker/test_processor.py tests/integration/test_reliability.py -v --no-cov

# Full suite
pytest tests/ -v --no-cov

# Import verification
python3 -c "from validation.errors import FieldUpdateWarning, PartialSyncResult; print('Errors OK')"
python3 -c "from worker.processor import SyncWorker; print('Processor OK')"

# Verify partial sync implemented
grep -n "PartialSyncResult" worker/processor.py && echo "Partial sync implemented"
grep -n "add_warning" worker/processor.py && echo "Warning aggregation implemented"
```
</verification>

<success_criteria>
- FieldUpdateWarning and PartialSyncResult classes exist in validation/errors.py
- _update_metadata uses granular try-except per field group
- Non-critical field failures logged as warnings, job succeeds
- Critical field failures (title) still fail the job
- Response validation catches potential silent failures
- All tests pass (new and existing)
- No regressions in existing functionality
</success_criteria>

<output>
After completion, create `.planning/phases/09-reliability-hardening/09-02-SUMMARY.md`
</output>
