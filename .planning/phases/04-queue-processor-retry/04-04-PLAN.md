---
phase: 04-queue-processor-retry
plan: 04
type: execute
wave: 3
depends_on: ["04-03"]
files_modified:
  - worker/processor.py
  - queue/dlq.py
autonomous: true

must_haves:
  truths:
    - "DLQ status logged periodically when jobs present"
    - "DLQ entries older than retention period are cleaned up"
    - "User can see recent DLQ entries in log output"
    - "Cleanup runs automatically on worker startup"
  artifacts:
    - path: "worker/processor.py"
      provides: "Worker with DLQ monitoring"
      contains: "_log_dlq_status"
    - path: "queue/dlq.py"
      provides: "DLQ with cleanup integration"
      exports: ["DeadLetterQueue"]
  key_links:
    - from: "worker/processor.py"
      to: "queue/dlq.py"
      via: "dlq.get_count() and dlq.get_recent()"
      pattern: "self\\.dlq\\.get_"
    - from: "worker/processor.py"
      to: "config.dlq_retention_days"
      via: "cleanup parameter"
      pattern: "dlq_retention_days"
---

<objective>
Add DLQ monitoring and cleanup to SyncWorker.

Purpose: Users need visibility into failed operations requiring manual intervention. Periodic DLQ status logging alerts users to problems. Automatic cleanup prevents unbounded growth.

Output: Worker logs DLQ status periodically, runs cleanup on startup using config retention days.
</objective>

<execution_context>
@/Users/trekkie/.claude/get-shit-done/workflows/execute-plan.md
@/Users/trekkie/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/phases/04-queue-processor-retry/04-RESEARCH.md

# Prior plan outputs
@.planning/phases/04-queue-processor-retry/04-03-SUMMARY.md

# Files to modify
@worker/processor.py
@queue/dlq.py
@validation/config.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Add DLQ status logging to worker</name>
  <files>worker/processor.py</files>
  <action>
Add DLQ monitoring to SyncWorker:

1. ADD status logging method:
```python
def _log_dlq_status(self):
    """Log DLQ status if jobs present."""
    count = self.dlq.get_count()
    if count > 0:
        print(f"[PlexSync Worker] WARNING: DLQ contains {count} failed jobs requiring review")
        recent = self.dlq.get_recent(limit=5)
        for entry in recent:
            print(
                f"  DLQ #{entry['id']}: scene {entry['scene_id']} - "
                f"{entry['error_type']}: {entry['error_message'][:80]}"
            )
```

2. ADD periodic logging (every N processed jobs or time interval):
```python
def __init__(self, ...):
    # ... existing ...
    self._jobs_since_dlq_log = 0
    self._dlq_log_interval = 10  # Log DLQ status every 10 jobs

def _worker_loop(self):
    # ... in success path after ack_job ...
    self._jobs_since_dlq_log += 1
    if self._jobs_since_dlq_log >= self._dlq_log_interval:
        self._log_dlq_status()
        self._jobs_since_dlq_log = 0
```

3. ADD DLQ logging on worker start (so user immediately sees backlog):
```python
def start(self):
    if self.running:
        print("[PlexSync Worker] Already running")
        return

    # Log DLQ status on startup
    self._log_dlq_status()

    self.running = True
    # ... rest of start ...
```
  </action>
  <verify>
```bash
python -c "from worker.processor import SyncWorker; print('DLQ logging methods exist')"
```
  </verify>
  <done>SyncWorker logs DLQ status on startup and every 10 processed jobs. Users see failed job summary in logs.</done>
</task>

<task type="auto">
  <name>Task 2: Add DLQ cleanup on worker startup</name>
  <files>worker/processor.py</files>
  <action>
Add automatic DLQ cleanup using config retention:

1. UPDATE start() to run cleanup:
```python
def start(self):
    if self.running:
        print("[PlexSync Worker] Already running")
        return

    # Cleanup old DLQ entries
    retention_days = getattr(self.config, 'dlq_retention_days', 30)
    self.dlq.delete_older_than(days=retention_days)

    # Log DLQ status on startup
    self._log_dlq_status()

    self.running = True
    self.thread = threading.Thread(target=self._worker_loop, daemon=True)
    self.thread.start()
    print("[PlexSync Worker] Started")
```

This ensures:
- Old entries cleaned up before status logging
- User sees current (post-cleanup) DLQ state
- No manual cleanup needed
  </action>
  <verify>
```bash
python -c "
from worker.processor import SyncWorker
from queue.dlq import DeadLetterQueue
import tempfile, os

# Create test setup
tmpdir = tempfile.mkdtemp()
dlq = DeadLetterQueue(tmpdir)

# Verify delete_older_than exists
dlq.delete_older_than(days=30)
print('DLQ cleanup works')
"
```
  </verify>
  <done>Worker runs DLQ cleanup on startup using config.dlq_retention_days. Old entries removed automatically.</done>
</task>

<task type="auto">
  <name>Task 3: Add worker __init__.py exports</name>
  <files>worker/__init__.py</files>
  <action>
Update `worker/__init__.py` to export new modules:

```python
"""
Worker module for background job processing.

Exports:
    SyncWorker: Background worker with retry orchestration
    CircuitBreaker: Circuit breaker for Plex outage protection
    CircuitState: Circuit breaker state enum
    calculate_delay: Exponential backoff delay calculator
    get_retry_params: Get retry parameters for error type
"""

from worker.processor import SyncWorker, TransientError, PermanentError
from worker.circuit_breaker import CircuitBreaker, CircuitState
from worker.backoff import calculate_delay, get_retry_params

__all__ = [
    'SyncWorker',
    'TransientError',
    'PermanentError',
    'CircuitBreaker',
    'CircuitState',
    'calculate_delay',
    'get_retry_params',
]
```
  </action>
  <verify>
```bash
python -c "from worker import SyncWorker, CircuitBreaker, calculate_delay; print('Exports OK')"
```
  </verify>
  <done>worker/__init__.py exports all new public APIs.</done>
</task>

</tasks>

<verification>
```bash
# All imports work
python -c "
from worker import SyncWorker, CircuitBreaker, CircuitState, calculate_delay, get_retry_params
from validation.config import PlexSyncConfig
print('All imports OK')
"

# DLQ logging works
python -c "
from worker.processor import SyncWorker
import inspect
assert '_log_dlq_status' in dir(SyncWorker), 'Missing _log_dlq_status method'
print('DLQ logging method exists')
"

# Run all Phase 4 tests
python -m pytest tests/test_backoff.py tests/test_circuit_breaker.py tests/test_retry_orchestration.py -v
```
</verification>

<success_criteria>
- [ ] Worker logs DLQ status on startup
- [ ] Worker logs DLQ status every 10 processed jobs
- [ ] DLQ cleanup runs on worker startup using config.dlq_retention_days
- [ ] worker/__init__.py exports CircuitBreaker, calculate_delay, get_retry_params
- [ ] All Phase 4 tests pass
</success_criteria>

<output>
After completion, create `.planning/phases/04-queue-processor-retry/04-04-SUMMARY.md`
</output>
