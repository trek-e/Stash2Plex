---
phase: 05-late-update-detection
plan: 03
type: execute
wave: 2
depends_on: ["05-01", "05-02"]
files_modified:
  - hooks/handlers.py
  - worker/processor.py
  - PlexSync.py
autonomous: true

must_haves:
  truths:
    - "Late metadata updates in Stash trigger re-sync to Plex"
    - "Matches scored with confidence level (HIGH auto-syncs, LOW logged for review)"
    - "User can review low-confidence matches in logs before manual sync"
    - "PlexSync.py wires sync timestamps to hook handler and worker"
  artifacts:
    - path: "hooks/handlers.py"
      provides: "Hook handler with timestamp check and deduplication"
      contains: "load_sync_timestamps"
    - path: "worker/processor.py"
      provides: "Worker with confidence handling and sync state updates"
      contains: "find_plex_items_with_confidence"
    - path: "PlexSync.py"
      provides: "Initialization wiring for sync timestamps"
      contains: "load_sync_timestamps"
  key_links:
    - from: "hooks/handlers.py"
      to: "queue/operations.py"
      via: "load_sync_timestamps call"
      pattern: "load_sync_timestamps"
    - from: "hooks/handlers.py"
      to: "hooks/handlers.py"
      via: "is_scene_pending/mark_scene_pending"
      pattern: "is_scene_pending|mark_scene_pending"
    - from: "worker/processor.py"
      to: "plex/matcher.py"
      via: "find_plex_items_with_confidence"
      pattern: "find_plex_items_with_confidence"
    - from: "worker/processor.py"
      to: "queue/operations.py"
      via: "save_sync_timestamp"
      pattern: "save_sync_timestamp"
    - from: "worker/processor.py"
      to: "hooks/handlers.py"
      via: "unmark_scene_pending"
      pattern: "unmark_scene_pending"
    - from: "PlexSync.py"
      to: "queue/operations.py"
      via: "load_sync_timestamps in initialize"
      pattern: "load_sync_timestamps"
---

<objective>
Integrate late update detection into hook handler and worker with confidence-based matching, and wire everything through PlexSync.py.

Purpose: Complete the late update detection feature by wiring timestamp checks, deduplication, confidence scoring, and sync state tracking into the existing hook and worker flows.

Output:
- Extended on_scene_update() with timestamp comparison and queue deduplication
- Extended _process_job() with confidence handling, strict_matching behavior, and sync state updates
- Extended _update_metadata() with simplified preserve_plex_edits conflict resolution (null-check only)
- Extended PlexSync.py initialize() to load sync timestamps and pass data_dir to components
</objective>

<execution_context>
@/Users/trekkie/.claude/get-shit-done/workflows/execute-plan.md
@/Users/trekkie/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/phases/05-late-update-detection/05-CONTEXT.md

# Prior plan summaries (need types/functions from these)
@.planning/phases/05-late-update-detection/05-01-SUMMARY.md
@.planning/phases/05-late-update-detection/05-02-SUMMARY.md

# Files to extend
@hooks/handlers.py
@worker/processor.py
@PlexSync.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Extend hook handler with timestamp check and deduplication</name>
  <files>hooks/handlers.py</files>
  <action>
Extend on_scene_update() in hooks/handlers.py to add late update detection.

1. Add import at top:
```python
from queue.operations import load_sync_timestamps
```

2. Update on_scene_update() signature to accept data_dir and sync_timestamps:
```python
def on_scene_update(
    scene_id: int,
    update_data: dict,
    queue,
    data_dir: Optional[str] = None,
    sync_timestamps: Optional[dict[int, float]] = None
) -> bool:
```

3. Add timestamp check after requires_plex_sync() filter:
```python
# Filter: Timestamp comparison for late update detection
if sync_timestamps is not None:
    # Try to get updated_at from Stash hook data
    # Fallback to current time if field missing (Stash may not always provide it)
    stash_updated_at = update_data.get('updated_at')
    if stash_updated_at is None:
        # Stash didn't provide updated_at - use current time as proxy
        # This means we'll re-sync, which is safe (idempotent)
        import time
        stash_updated_at = time.time()

    last_synced = sync_timestamps.get(scene_id)
    if last_synced and stash_updated_at <= last_synced:
        print(f"[PlexSync] Scene {scene_id} already synced (Stash: {stash_updated_at} <= Last: {last_synced})")
        return False
```

4. Add queue deduplication check before enqueue (uses is_scene_pending from same module):
```python
# Filter: Queue deduplication using in-memory tracking
if is_scene_pending(scene_id):
    print(f"[PlexSync] Scene {scene_id} already in queue, skipping duplicate")
    return False
```

5. After successful enqueue, call mark_scene_pending(scene_id).

Place these checks AFTER requires_plex_sync() but BEFORE validation and enqueue logic.
Maintain <100ms target - timestamp dict lookup and set check are O(1).
  </action>
  <verify>
python -c "from hooks.handlers import on_scene_update; import inspect; sig = inspect.signature(on_scene_update); print(f'Params: {list(sig.parameters.keys())}'); assert 'sync_timestamps' in sig.parameters; print('Hook handler: PASS')"
  </verify>
  <done>on_scene_update() includes timestamp comparison and queue deduplication checks</done>
</task>

<task type="auto">
  <name>Task 2: Extend worker with confidence handling and sync state updates</name>
  <files>worker/processor.py</files>
  <action>
Extend SyncWorker in worker/processor.py to use confidence-based matching.

1. Add data_dir to __init__():
```python
def __init__(
    self,
    queue,
    dlq: 'DeadLetterQueue',
    config: 'PlexSyncConfig',
    data_dir: Optional[str] = None,  # NEW
    max_retries: int = 5,
):
    # ... existing code ...
    self.data_dir = data_dir  # NEW
```

2. Add imports at top:
```python
import logging
from queue.operations import save_sync_timestamp
from hooks.handlers import unmark_scene_pending

logger = logging.getLogger('PlexSync.worker')
```

3. Rewrite _process_job() to use confidence-based matching:

```python
def _process_job(self, job: dict):
    from plex.exceptions import PlexTemporaryError, PlexPermanentError, PlexNotFound, translate_plex_exception
    from plex.matcher import find_plex_items_with_confidence, MatchConfidence

    scene_id = job.get('scene_id')
    data = job.get('data', {})
    file_path = data.get('path')

    if not file_path:
        raise PermanentError(f"Job {scene_id} missing file path")

    try:
        client = self._get_plex_client()

        # Search all library sections, collect ALL candidates
        all_candidates = []
        for section in client.server.library.sections():
            try:
                confidence, item, candidates = find_plex_items_with_confidence(section, file_path)
                all_candidates.extend(candidates)
            except PlexNotFound:
                continue  # No match in this section, try next

        # Deduplicate candidates (same item might be in multiple sections)
        seen_keys = set()
        unique_candidates = []
        for c in all_candidates:
            if c.key not in seen_keys:
                seen_keys.add(c.key)
                unique_candidates.append(c)

        # Apply confidence scoring
        if len(unique_candidates) == 0:
            raise PlexNotFound(f"Could not find Plex item for path: {file_path}")
        elif len(unique_candidates) == 1:
            # HIGH confidence - single unique match
            plex_item = unique_candidates[0]
            self._update_metadata(plex_item, data)
        else:
            # LOW confidence - multiple matches
            paths = [c.media[0].parts[0].file if c.media and c.media[0].parts else c.key for c in unique_candidates]
            if self.config.strict_matching:
                logger.warning(
                    f"[PlexSync] LOW CONFIDENCE SKIPPED: scene {scene_id}\n"
                    f"  Stash path: {file_path}\n"
                    f"  Plex candidates ({len(unique_candidates)}): {paths}"
                )
                raise PermanentError(f"Low confidence match skipped (strict_matching=true)")
            else:
                plex_item = unique_candidates[0]
                logger.warning(
                    f"[PlexSync] LOW CONFIDENCE SYNCED: scene {scene_id}\n"
                    f"  Chosen: {paths[0]}\n"
                    f"  Other candidates: {paths[1:]}"
                )
                self._update_metadata(plex_item, data)

        # Update sync timestamp after successful sync
        if self.data_dir is not None:
            import time
            save_sync_timestamp(self.data_dir, scene_id, time.time())

        # Remove from pending set (always, even on failure - will be re-added on retry)
        unmark_scene_pending(scene_id)

    except (PlexTemporaryError, PlexPermanentError, PlexNotFound):
        unmark_scene_pending(scene_id)  # Allow re-enqueue on next hook
        raise
    except Exception as e:
        unmark_scene_pending(scene_id)
        raise translate_plex_exception(e)
```

4. Simplify _update_metadata() for preserve_plex_edits (null-check only per user decision):
```python
def _update_metadata(self, plex_item, data: dict):
    edits = {}

    if self.config.preserve_plex_edits:
        # Only update fields that are None or empty string in Plex
        # Simplified logic: any existing value = preserve it
        if 'title' in data:
            if not plex_item.title:  # None or empty string
                edits['title.value'] = data['title']
        if 'studio' in data:
            if not plex_item.studio:
                edits['studio.value'] = data['studio']
        if 'summary' in data:
            if not plex_item.summary:
                edits['summary.value'] = data['summary']
        if 'tagline' in data:
            if not getattr(plex_item, 'tagline', None):
                edits['tagline.value'] = data['tagline']
    else:
        # Stash always wins - overwrite all fields
        if 'title' in data:
            edits['title.value'] = data['title']
        if 'studio' in data:
            edits['studio.value'] = data['studio']
        if 'summary' in data:
            edits['summary.value'] = data['summary']
        if 'tagline' in data:
            edits['tagline.value'] = data['tagline']

    if edits:
        plex_item.edit(**edits)
        plex_item.reload()
        mode = "preserved" if self.config.preserve_plex_edits else "overwrite"
        print(f"[PlexSync Worker] Updated metadata ({mode} mode): {plex_item.title}")
```

Note: preserve_plex_edits now uses simple null-check only (None or empty string = allow update). No complex "default value" detection.
  </action>
  <verify>
python -c "from worker.processor import SyncWorker; import inspect; sig = inspect.signature(SyncWorker.__init__); print(f'Params: {list(sig.parameters.keys())}'); assert 'data_dir' in sig.parameters; print('Worker: PASS')"
  </verify>
  <done>SyncWorker uses confidence-based matching, respects strict_matching config, updates sync timestamps, uses simplified preserve_plex_edits</done>
</task>

<task type="auto">
  <name>Task 3: Wire sync timestamps through PlexSync.py</name>
  <files>PlexSync.py</files>
  <action>
Update PlexSync.py to load sync timestamps at startup and pass data_dir to hook handler and worker.

1. Add import at top:
```python
from queue.operations import load_sync_timestamps
```

2. Add module-level variable for sync timestamps:
```python
sync_timestamps: dict = None
```

3. Update initialize() to load sync timestamps and pass data_dir to worker:
```python
def initialize(config_dict: dict = None):
    global queue_manager, dlq, worker, config, sync_timestamps

    # ... existing validation code ...

    data_dir = get_plugin_data_dir()
    print(f"[PlexSync] Initializing with data directory: {data_dir}")

    # Load sync timestamps for late update detection
    sync_timestamps = load_sync_timestamps(data_dir)
    print(f"[PlexSync] Loaded {len(sync_timestamps)} sync timestamps")

    # Initialize queue infrastructure
    queue_manager = QueueManager(data_dir)
    dlq = DeadLetterQueue(data_dir)

    # Start background worker with data_dir for timestamp updates
    worker = SyncWorker(
        queue_manager.get_queue(),
        dlq,
        config,
        data_dir=data_dir,  # NEW - for save_sync_timestamp calls
        max_retries=config.max_retries
    )
    worker.start()
```

4. Update handle_hook() to pass data_dir and sync_timestamps to on_scene_update():
```python
def handle_hook(hook_context: dict):
    global sync_timestamps

    hook_type = hook_context.get("type", "")
    input_data = hook_context.get("input", {})

    if hook_type == "Scene.Update.Post":
        scene_id = input_data.get("id")
        if scene_id:
            data_dir = get_plugin_data_dir()
            on_scene_update(
                scene_id,
                input_data,
                queue_manager.get_queue(),
                data_dir=data_dir,
                sync_timestamps=sync_timestamps
            )
        else:
            print("[PlexSync] WARNING: Scene.Update.Post hook missing scene ID")
    else:
        print(f"[PlexSync] Unhandled hook type: {hook_type}")
```

This completes the wiring so that:
- Hook handler can compare timestamps before enqueuing
- Worker can save timestamps after successful sync
- Both use the same data directory for the sync_timestamps.json file
  </action>
  <verify>
python -c "import PlexSync; print('PlexSync imports OK'); import inspect; src = inspect.getsource(PlexSync.initialize); assert 'load_sync_timestamps' in src; assert 'data_dir' in src; print('Wiring: PASS')"
  </verify>
  <done>PlexSync.py loads sync timestamps at startup and passes data_dir to hook handler and worker</done>
</task>

</tasks>

<verification>
Run all verification commands:
```bash
# Test hook handler signature
python -c "from hooks.handlers import on_scene_update; import inspect; sig = inspect.signature(on_scene_update); params = list(sig.parameters.keys()); assert 'sync_timestamps' in params; assert 'data_dir' in params; print('Hook handler: PASS')"

# Test worker signature
python -c "from worker.processor import SyncWorker; import inspect; sig = inspect.signature(SyncWorker.__init__); params = list(sig.parameters.keys()); assert 'data_dir' in params; print('Worker: PASS')"

# Test PlexSync wiring
python -c "import PlexSync; import inspect; src = inspect.getsource(PlexSync.initialize); assert 'load_sync_timestamps' in src; print('PlexSync wiring: PASS')"

# Verify existing tests still pass
python -m pytest tests/ -v --tb=short 2>/dev/null || echo "Check test output"
```
</verification>

<success_criteria>
1. on_scene_update() accepts data_dir and sync_timestamps parameters
2. on_scene_update() compares updated_at vs sync_timestamps before enqueue
3. on_scene_update() falls back to time.time() if updated_at missing from Stash
4. on_scene_update() calls is_scene_pending() before enqueue
5. on_scene_update() calls mark_scene_pending() after enqueue
6. SyncWorker.__init__() accepts data_dir parameter
7. _process_job() uses find_plex_items_with_confidence()
8. _process_job() respects strict_matching config for LOW confidence matches
9. _process_job() calls save_sync_timestamp() after successful sync
10. _process_job() calls unmark_scene_pending() after job completes
11. _update_metadata() uses simplified null-check for preserve_plex_edits
12. PlexSync.initialize() loads sync_timestamps with load_sync_timestamps()
13. PlexSync.handle_hook() passes data_dir and sync_timestamps to on_scene_update()
14. PlexSync passes data_dir to SyncWorker constructor
15. LOW confidence matches logged with scene ID, Stash path, and candidate list
16. Existing tests pass (no regressions)
</success_criteria>

<output>
After completion, create `.planning/phases/05-late-update-detection/05-03-SUMMARY.md`
</output>
