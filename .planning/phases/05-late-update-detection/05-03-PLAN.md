---
phase: 05-late-update-detection
plan: 03
type: execute
wave: 2
depends_on: ["05-01", "05-02"]
files_modified:
  - hooks/handlers.py
  - worker/processor.py
autonomous: true

must_haves:
  truths:
    - "Late metadata updates in Stash trigger re-sync to Plex"
    - "Matches scored with confidence level (HIGH auto-syncs, LOW logged for review)"
    - "User can review low-confidence matches in logs before manual sync"
  artifacts:
    - path: "hooks/handlers.py"
      provides: "Hook handler with timestamp check and deduplication"
      contains: "get_last_synced_at"
    - path: "worker/processor.py"
      provides: "Worker with confidence handling and sync state updates"
      contains: "find_plex_items_with_confidence"
  key_links:
    - from: "hooks/handlers.py"
      to: "sync/state.py"
      via: "SyncState.get_last_synced_at"
      pattern: "get_last_synced_at"
    - from: "hooks/handlers.py"
      to: "queue/operations.py"
      via: "is_scene_in_queue check"
      pattern: "is_scene_in_queue"
    - from: "worker/processor.py"
      to: "plex/matcher.py"
      via: "find_plex_items_with_confidence"
      pattern: "find_plex_items_with_confidence"
    - from: "worker/processor.py"
      to: "sync/state.py"
      via: "SyncState.update_success"
      pattern: "update_success"
---

<objective>
Integrate late update detection into hook handler and worker with confidence-based matching.

Purpose: Complete the late update detection feature by wiring timestamp checks, deduplication, confidence scoring, and sync state tracking into the existing hook and worker flows.

Output:
- Extended on_scene_update() with timestamp comparison and queue deduplication
- Extended _process_job() with confidence handling, strict_matching behavior, and sync state updates
- Extended _update_metadata() with preserve_plex_edits conflict resolution
</objective>

<execution_context>
@/Users/trekkie/.claude/get-shit-done/workflows/execute-plan.md
@/Users/trekkie/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/phases/05-late-update-detection/05-CONTEXT.md
@.planning/phases/05-late-update-detection/05-RESEARCH.md

# Prior plan summaries (need types/functions from these)
@.planning/phases/05-late-update-detection/05-01-SUMMARY.md
@.planning/phases/05-late-update-detection/05-02-SUMMARY.md

# Files to extend
@hooks/handlers.py
@worker/processor.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Extend hook handler with timestamp check and deduplication</name>
  <files>hooks/handlers.py</files>
  <action>
Extend on_scene_update() in hooks/handlers.py to add late update detection.

1. Add imports at top (with lazy try/except pattern):
```python
try:
    from queue.operations import is_scene_in_queue
except ImportError:
    is_scene_in_queue = None

try:
    from sync.state import SyncState
except ImportError:
    SyncState = None
```

2. Update on_scene_update() signature to accept optional sync_state parameter:
```python
def on_scene_update(
    scene_id: int,
    update_data: dict,
    queue,
    sync_state: Optional['SyncState'] = None
) -> bool:
```

3. Add timestamp check after requires_plex_sync() filter:
```python
# Filter: Timestamp comparison for late update detection
if sync_state is not None:
    stash_updated_at = update_data.get('updated_at')
    if stash_updated_at:
        last_synced = sync_state.get_last_synced_at(scene_id)
        if last_synced and stash_updated_at <= last_synced:
            print(f"[PlexSync] Scene {scene_id} already synced (Stash: {stash_updated_at} <= Last: {last_synced})")
            return False
```

4. Add queue deduplication check before enqueue:
```python
# Filter: Queue deduplication
if is_scene_in_queue is not None and hasattr(queue, 'path'):
    if is_scene_in_queue(queue.path, scene_id):
        print(f"[PlexSync] Scene {scene_id} already in queue, skipping duplicate")
        return False
```

Place these checks AFTER requires_plex_sync() but BEFORE validation and enqueue logic.
Maintain <100ms target - timestamp check and dedup are fast SQLite queries.
  </action>
  <verify>
python -c "from hooks.handlers import on_scene_update, requires_plex_sync; print('Hook handler imports OK')"
  </verify>
  <done>on_scene_update() includes timestamp comparison and queue deduplication checks</done>
</task>

<task type="auto">
  <name>Task 2: Extend worker with confidence handling and sync state updates</name>
  <files>worker/processor.py</files>
  <action>
Extend SyncWorker in worker/processor.py to use confidence-based matching.

1. Add SyncState to __init__():
```python
def __init__(
    self,
    queue,
    dlq: 'DeadLetterQueue',
    config: 'PlexSyncConfig',
    sync_state: Optional['SyncState'] = None,  # NEW
    max_retries: int = 5,
):
    # ... existing code ...
    self.sync_state = sync_state  # NEW
```

2. Rewrite _process_job() to use confidence-based matching:

```python
def _process_job(self, job: dict):
    # Import with lazy loading
    from plex.exceptions import PlexTemporaryError, PlexPermanentError, PlexNotFound, translate_plex_exception
    from plex.matcher import find_plex_items_with_confidence, MatchConfidence

    scene_id = job.get('scene_id')
    update_type = job.get('update_type')
    data = job.get('data', {})
    file_path = data.get('path')

    if not file_path:
        raise PermanentError(f"Job {scene_id} missing file path")

    try:
        client = self._get_plex_client()

        # Search all library sections, collect ALL candidates
        all_candidates = []
        for section in client.server.library.sections():
            try:
                confidence, item, candidates = find_plex_items_with_confidence(section, file_path)
                all_candidates.extend(candidates)
            except PlexNotFound:
                continue  # No match in this section, try next

        # Deduplicate candidates (same item might be in multiple sections)
        seen_keys = set()
        unique_candidates = []
        for c in all_candidates:
            if c.key not in seen_keys:
                seen_keys.add(c.key)
                unique_candidates.append(c)

        # Apply confidence scoring
        if len(unique_candidates) == 0:
            raise PlexNotFound(f"Could not find Plex item for path: {file_path}")
        elif len(unique_candidates) == 1:
            # HIGH confidence - single unique match
            plex_item = unique_candidates[0]
            self._update_metadata(plex_item, data)
        else:
            # LOW confidence - multiple matches
            paths = [c.media[0].parts[0].file if c.media and c.media[0].parts else c.key for c in unique_candidates]
            if self.config.strict_matching:
                logger.warning(
                    f"[PlexSync] LOW CONFIDENCE SKIPPED: scene {scene_id}\n"
                    f"  Stash path: {file_path}\n"
                    f"  Plex candidates ({len(unique_candidates)}): {paths}"
                )
                raise PermanentError(f"Low confidence match skipped (strict_matching=true)")
            else:
                plex_item = unique_candidates[0]
                logger.warning(
                    f"[PlexSync] LOW CONFIDENCE SYNCED: scene {scene_id}\n"
                    f"  Chosen: {paths[0]}\n"
                    f"  Other candidates: {paths[1:]}"
                )
                self._update_metadata(plex_item, data)

        # Update sync state after successful sync
        if self.sync_state is not None:
            self.sync_state.update_success(scene_id, plex_item.key)

    except (PlexTemporaryError, PlexPermanentError, PlexNotFound):
        raise
    except Exception as e:
        raise translate_plex_exception(e)
```

3. Add import for logging at top:
```python
import logging
logger = logging.getLogger('PlexSync.worker')
```

4. Extend _update_metadata() for preserve_plex_edits:
```python
def _update_metadata(self, plex_item, data: dict):
    edits = {}

    if self.config.preserve_plex_edits:
        # Only update fields that are empty/default in Plex
        if 'title' in data:
            # Check if Plex title is default (filename) or empty
            has_default_title = not plex_item.title or (
                plex_item.media and plex_item.media[0].parts and
                plex_item.title == plex_item.media[0].parts[0].file.split('/')[-1]
            )
            if has_default_title:
                edits['title.value'] = data['title']
        if 'studio' in data and not plex_item.studio:
            edits['studio.value'] = data['studio']
        if 'summary' in data and not plex_item.summary:
            edits['summary.value'] = data['summary']
        if 'tagline' in data and not getattr(plex_item, 'tagline', None):
            edits['tagline.value'] = data['tagline']
    else:
        # Stash always wins - overwrite all fields
        if 'title' in data:
            edits['title.value'] = data['title']
        if 'studio' in data:
            edits['studio.value'] = data['studio']
        if 'summary' in data:
            edits['summary.value'] = data['summary']
        if 'tagline' in data:
            edits['tagline.value'] = data['tagline']

    if edits:
        plex_item.edit(**edits)
        plex_item.reload()
        mode = "preserved" if self.config.preserve_plex_edits else "overwrite"
        print(f"[PlexSync Worker] Updated metadata ({mode} mode): {plex_item.title}")
```
  </action>
  <verify>
python -c "from worker.processor import SyncWorker; print('Worker imports OK')"
  </verify>
  <done>SyncWorker uses confidence-based matching, respects strict_matching config, updates sync state after success</done>
</task>

</tasks>

<verification>
Run all verification commands:
```bash
# Test hook handler imports
python -c "from hooks.handlers import on_scene_update; import inspect; sig = inspect.signature(on_scene_update); print(f'Params: {list(sig.parameters.keys())}'); assert 'sync_state' in sig.parameters; print('Hook handler: PASS')"

# Test worker imports
python -c "from worker.processor import SyncWorker; import inspect; sig = inspect.signature(SyncWorker.__init__); print(f'Params: {list(sig.parameters.keys())}'); print('Worker: PASS')"

# Verify existing tests still pass
python -m pytest tests/ -v --tb=short 2>/dev/null || echo "Check test output"
```
</verification>

<success_criteria>
1. on_scene_update() accepts optional sync_state parameter
2. on_scene_update() compares updated_at vs last_synced_at before enqueue
3. on_scene_update() checks is_scene_in_queue() before enqueue
4. SyncWorker.__init__() accepts optional sync_state parameter
5. _process_job() uses find_plex_items_with_confidence()
6. _process_job() respects strict_matching config for LOW confidence matches
7. _process_job() calls sync_state.update_success() after successful sync
8. _update_metadata() respects preserve_plex_edits config
9. LOW confidence matches logged with scene ID, Stash path, and candidate list
10. Existing tests pass (no regressions)
</success_criteria>

<output>
After completion, create `.planning/phases/05-late-update-detection/05-03-SUMMARY.md`
</output>
