---
phase: 18-health-check-infrastructure
plan: 02
type: execute
wave: 2
depends_on: ["18-01"]
files_modified:
  - Stash2Plex.py
  - Stash2Plex.yml
  - worker/processor.py
  - tests/worker/test_processor.py
  - tests/test_stash2plex.py
autonomous: true

must_haves:
  truths:
    - "Manual 'Health Check' task in Stash UI shows circuit breaker state, Plex connectivity, and queue size"
    - "Worker loop runs active health checks during OPEN state to detect Plex recovery"
    - "Health check interval uses exponential backoff during extended outages (5s base, 60s cap)"
    - "Health check interval resets to 5s after successful health check"
    - "Passive monitoring (job results) continues alongside active probes (hybrid monitoring)"
  artifacts:
    - path: "Stash2Plex.py"
      provides: "handle_health_check() function and health_check mode in dispatch table"
      contains: "health_check"
    - path: "Stash2Plex.yml"
      provides: "Health Check task definition for Stash UI"
      contains: "Health Check"
    - path: "worker/processor.py"
      provides: "Active health check integration in _worker_loop during OPEN state"
      contains: "check_plex_health"
  key_links:
    - from: "Stash2Plex.py"
      to: "plex/health.py"
      via: "import check_plex_health for manual health check"
      pattern: "from plex\\.health import check_plex_health"
    - from: "worker/processor.py"
      to: "plex/health.py"
      via: "import check_plex_health for active probes during OPEN"
      pattern: "from plex\\.health import check_plex_health"
    - from: "worker/processor.py"
      to: "worker/backoff.py"
      via: "calculate_delay for health check interval backoff"
      pattern: "calculate_delay"
---

<objective>
Wire health checks into the manual task UI and worker loop for hybrid monitoring.

Purpose: Manual task gives users on-demand visibility into Plex connectivity. Worker loop integration enables automatic recovery detection during outages via active health probes, complementing existing passive monitoring (job results). Exponential backoff prevents resource waste during long outages.

Output: Manual health check task in Stash UI + active health probes in worker loop with backoff.
</objective>

<execution_context>
@/Users/trekkie/.claude/get-shit-done/workflows/execute-plan.md
@/Users/trekkie/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/18-health-check-infrastructure/18-01-SUMMARY.md
@Stash2Plex.py
@Stash2Plex.yml
@worker/processor.py
@worker/backoff.py
@worker/circuit_breaker.py
@plex/health.py
@tests/worker/test_processor.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Add manual health check task to Stash UI</name>
  <files>Stash2Plex.py, Stash2Plex.yml</files>
  <action>
    1. In Stash2Plex.yml, add a new task entry between "Process Queue" and "Reconcile Library (All)":
       ```yaml
       - name: Health Check
         description: Check Plex server connectivity and circuit breaker status
         defaultArgs:
           mode: health_check
       ```

    2. In Stash2Plex.py, add 'health_check' to _MANAGEMENT_HANDLERS dispatch table:
       ```python
       'health_check': lambda args: handle_health_check(),
       ```

    3. Create handle_health_check() function in Stash2Plex.py (add before _MANAGEMENT_HANDLERS dict).
       The function should:
       - Log "=== Plex Health Check ==="
       - Report circuit breaker state by reading circuit_breaker.json from data_dir:
         * If file exists: parse state, log "Circuit Breaker State: {STATE}" (uppercase)
         * If state is "open" and opened_at exists: calculate elapsed time, log how long ago
         * If file doesn't exist: log "Circuit Breaker State: CLOSED (no state file)"
         * If file is corrupted: log "Circuit Breaker State: UNKNOWN (corrupted state file)"
       - Create PlexClient with short timeouts (5s connect, 5s read) for health probe:
         ```python
         from plex.client import PlexClient
         from plex.health import check_plex_health
         client = PlexClient(
             url=config.plex_url,
             token=config.plex_token,
             connect_timeout=5.0,
             read_timeout=5.0
         )
         ```
       - Call check_plex_health(client, timeout=5.0)
       - If healthy: log_info("Plex is HEALTHY (responded in {latency_ms:.0f}ms)")
       - If not healthy: log_warn("Plex is UNREACHABLE") + log_info("Verify Plex URL and network connectivity")
       - Report queue size if queue_manager is available:
         * Get queue size via queue_manager.get_queue().size
         * If pending > 0 and circuit is open: log_warn about jobs waiting
       - Log "=== Health Check Complete ==="
       - Wrap entire function in try/except, log_error on failure

    4. Also add 'health_check' to the management_modes set in main() (around line 1164) so the
       worker drain timeout is skipped for this diagnostic task.

    IMPORTANT: Do NOT use emoji characters in log messages. Use text markers like "OK:" and "FAIL:" instead. Stash log viewer may not render emoji correctly.
  </action>
  <verify>
    ```bash
    # Verify health_check mode is in dispatch table
    cd /Users/trekkie/projects/PlexSync && python -c "
    import ast, sys
    with open('Stash2Plex.py') as f:
        content = f.read()
    assert 'health_check' in content, 'health_check mode not found'
    assert 'handle_health_check' in content, 'handle_health_check function not found'
    print('OK: health_check handler present')
    "
    # Verify yml has Health Check task
    grep -c "Health Check" Stash2Plex.yml
    # Run existing tests to check no regressions
    cd /Users/trekkie/projects/PlexSync && python -m pytest tests/test_stash2plex.py -v --timeout=60 2>&1 | tail -5
    ```
  </verify>
  <done>
    - Stash2Plex.yml has "Health Check" task with mode: health_check
    - handle_health_check() reads CB state, tests Plex connectivity, reports queue size
    - health_check is in _MANAGEMENT_HANDLERS and management_modes set
    - No regressions in existing tests
  </done>
</task>

<task type="auto">
  <name>Task 2: Integrate active health probes into worker loop with backoff</name>
  <files>worker/processor.py, tests/worker/test_processor.py</files>
  <action>
    Modify SyncWorker._worker_loop() to add active health checks during OPEN circuit state.

    1. Add instance variables to SyncWorker.__init__():
       ```python
       # Health check state for active probes during OPEN circuit
       self._last_health_check: float = 0.0
       self._health_check_interval: float = 5.0  # Initial: 5s
       self._consecutive_health_failures: int = 0
       ```

    2. In _worker_loop(), modify the existing OPEN circuit handling block (currently around lines 300-311).
       Currently the code sleeps for poll_interval when circuit is OPEN. Replace with active health probe logic:

       When circuit breaker says can_execute() is False (OPEN state):
       a. Check if enough time has elapsed since last health check:
          `now = time.time(); if now - self._last_health_check >= self._health_check_interval:`
       b. If due, run health check:
          ```python
          from plex.health import check_plex_health
          client = self._get_plex_client()
          is_healthy, latency_ms = check_plex_health(client, timeout=5.0)
          self._last_health_check = now
          ```
       c. On success (is_healthy=True):
          - Log at info level: "Plex health check passed ({latency_ms:.0f}ms), recovery possible"
          - Reset: self._consecutive_health_failures = 0
          - Reset: self._health_check_interval = 5.0
          - NOTE: Do NOT directly modify circuit breaker state. The circuit breaker's own
            recovery_timeout handles OPEN->HALF_OPEN transition. The health check success
            is informational â€” it tells us Plex is back, and the next can_execute() call
            will naturally transition to HALF_OPEN if timeout has elapsed.
       d. On failure (is_healthy=False):
          - self._consecutive_health_failures += 1
          - Calculate next interval using worker/backoff.py:
            ```python
            from worker.backoff import calculate_delay
            self._health_check_interval = calculate_delay(
                retry_count=self._consecutive_health_failures,
                base=5.0,
                cap=60.0,
                jitter_seed=None  # Random jitter in production
            )
            ```
          - Log at debug level: "Plex health check failed (attempt #{n}), next check in {interval:.1f}s"
       e. After health check (or if not due yet), sleep in small increments (0.5s) for
          responsive shutdown, same as current pattern. Keep the existing interruptible
          sleep loop pattern:
          ```python
          for _ in range(int(self.config.poll_interval * 2)):
              if not self.running:
                  return
              time.sleep(0.5)
          ```

    3. Add tests to tests/worker/test_processor.py:
       - Test: health check runs when circuit is OPEN and interval has elapsed
       - Test: health check does NOT run when interval hasn't elapsed
       - Test: successful health check resets interval to 5s and failure counter to 0
       - Test: failed health check increases interval via backoff (mock calculate_delay)
       - Test: consecutive failures track correctly
       - Test: health check uses 5s timeout (not 30s read_timeout)
       - Use unittest.mock to mock check_plex_health and time.time for deterministic tests
       - Follow existing test patterns in test_processor.py (conftest fixtures, mock_stash_gql, etc.)

    CRITICAL DESIGN NOTES:
    - Health check should NOT directly call circuit_breaker.record_success() or modify CB state.
      Research pitfall #3 warns about race conditions. Let the circuit breaker's own state property
      handle OPEN->HALF_OPEN transition based on recovery_timeout.
    - Health check import should be at method level (lazy) to avoid module-level import pollution,
      consistent with existing worker/processor.py patterns.
    - Use _get_plex_client() which already handles lazy initialization with correct timeouts.
      However, the health check passes its own timeout=5.0 to server.query(), overriding the
      client's read_timeout for this specific call.
  </action>
  <verify>
    ```bash
    cd /Users/trekkie/projects/PlexSync && python -m pytest tests/worker/test_processor.py -v -k "health" --timeout=60
    cd /Users/trekkie/projects/PlexSync && python -m pytest tests/ -x --timeout=60
    ```
  </verify>
  <done>
    - Worker loop runs active health checks during OPEN state at configurable intervals
    - Health check interval starts at 5s and backs off exponentially to 60s cap on failures
    - Interval resets to 5s on successful health check
    - Health check does NOT directly modify circuit breaker state (avoids race condition)
    - New tests cover: interval timing, backoff calculation, success/failure handling, timeout value
    - All existing tests pass (no regressions)
  </done>
</task>

</tasks>

<verification>
```bash
# Full test suite
cd /Users/trekkie/projects/PlexSync && python -m pytest tests/ -x --timeout=120

# Verify health check in Stash UI config
grep "Health Check" /Users/trekkie/projects/PlexSync/Stash2Plex.yml

# Verify health check in dispatch table
grep "health_check" /Users/trekkie/projects/PlexSync/Stash2Plex.py

# Verify active health probes in worker
grep "check_plex_health" /Users/trekkie/projects/PlexSync/worker/processor.py

# Verify backoff integration
grep "calculate_delay" /Users/trekkie/projects/PlexSync/worker/processor.py
```
</verification>

<success_criteria>
- "Health Check" task appears in Stash2Plex.yml
- handle_health_check() reports circuit state + connectivity + queue size
- Worker loop actively probes Plex during OPEN state
- Health check interval follows exponential backoff (5s -> 10s -> 20s -> 40s -> 60s cap)
- All tests pass including new health check tests
- No regressions in existing test suite
</success_criteria>

<output>
After completion, create `.planning/phases/18-health-check-infrastructure/18-02-SUMMARY.md`
</output>
