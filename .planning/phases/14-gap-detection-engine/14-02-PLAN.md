---
phase: 14-gap-detection-engine
plan: 02
type: execute
wave: 2
depends_on: ["14-01"]
files_modified:
  - reconciliation/detector.py
  - reconciliation/engine.py
  - tests/reconciliation/test_engine.py
autonomous: true

must_haves:
  truths:
    - "Gap engine fetches all Stash scenes via GQL and runs all three gap detectors"
    - "Detected gaps are enqueued as standard sync jobs through the existing persistent queue"
    - "Gap engine uses lighter pre-check for missing detection: sync_timestamps first, then matcher only for unknowns"
    - "Gap engine deduplicates against items already in queue before enqueuing"
    - "Gap engine returns a summary with counts by gap type"
  artifacts:
    - path: "reconciliation/engine.py"
      provides: "GapDetectionEngine class that orchestrates detection and enqueue"
      min_lines: 100
    - path: "tests/reconciliation/test_engine.py"
      provides: "Tests for engine orchestration, enqueue integration, deduplication"
      min_lines: 100
  key_links:
    - from: "reconciliation/engine.py"
      to: "reconciliation/detector.py"
      via: "GapDetector instantiation and method calls"
      pattern: "GapDetector"
    - from: "reconciliation/engine.py"
      to: "sync_queue/operations.py"
      via: "enqueue() for gap jobs, load_sync_timestamps(), get_queued_scene_ids()"
      pattern: "from sync_queue.operations import"
    - from: "reconciliation/engine.py"
      to: "plex/matcher.py"
      via: "find_plex_items_with_confidence for missing detection"
      pattern: "find_plex_items_with_confidence"
---

<objective>
Wire the GapDetector (from Plan 01) into a GapDetectionEngine that orchestrates end-to-end gap detection: fetch Stash scenes, match against Plex, run detectors, and enqueue discovered gaps.

Purpose: This is the integration layer that connects the pure detection logic to real infrastructure (Stash GQL, Plex matcher, persistent queue). After this plan, the gap detection engine is fully functional and ready for Phase 15's manual reconciliation trigger.

Output: Working GapDetectionEngine class in `reconciliation/engine.py` with tests.
</objective>

<execution_context>
@/Users/trekkie/.claude/get-shit-done/workflows/execute-plan.md
@/Users/trekkie/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/14-gap-detection-engine/14-CONTEXT.md
@.planning/phases/14-gap-detection-engine/14-01-SUMMARY.md
@reconciliation/detector.py
@sync_queue/operations.py
@plex/matcher.py
@plex/cache.py
@plex/client.py
@Stash2Plex.py
@hooks/handlers.py
@tests/conftest.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: GapDetectionEngine orchestrator with Stash/Plex integration</name>
  <files>reconciliation/engine.py, reconciliation/__init__.py</files>
  <action>
    Create `reconciliation/engine.py` with a GapDetectionEngine class that orchestrates the full detection pipeline:

    **Constructor: __init__(self, stash, config, data_dir, queue=None)**
    - stash: StashInterface instance (for GQL scene queries)
    - config: Stash2PlexConfig (for Plex connection details, library names)
    - data_dir: Plugin data directory (for sync_timestamps.json, queue path)
    - queue: Optional SQLiteAckQueue (if provided, gaps are enqueued; if None, detection-only mode)

    **Main method: run(self, scope="all") -> GapDetectionResult**
    - scope: "all" or "recent" (recent = last 24 hours, matching existing handle_task pattern from Stash2Plex.py lines 814-824)
    - Steps:
      1. Fetch Stash scenes via stash.find_scenes() with the batch fragment (reuse exact fragment from Stash2Plex.py lines 799-811, including updated_at)
      2. Load sync_timestamps via load_sync_timestamps(data_dir)
      3. Build Plex item metadata for empty detection:
         - Create PlexClient from config
         - For each configured library, get all items (use library_cache if available)
         - Build dict mapping file_path -> {studio, performers/actors, tags/genres, details/summary, date}
         - This is needed for detect_empty_metadata
      4. Build matched_paths set for missing detection (lighter pre-check):
         - Start with all file paths that have entries in sync_timestamps (known matches)
         - For scenes NOT in sync_timestamps, check match_cache (from plex/cache.py MatchCache)
         - For scenes still unknown, run find_plex_items_with_confidence (full matcher)
         - Collect all file paths that have Plex matches into matched_paths set
         - Also collect Plex item metadata from matched items for step 3
      5. Run GapDetector.detect_empty_metadata(stash_scenes, plex_items_metadata)
      6. Run GapDetector.detect_stale_syncs(stash_scenes, sync_timestamps)
      7. Run GapDetector.detect_missing(stash_scenes, sync_timestamps, matched_paths)
      8. If queue provided: enqueue each gap as a standard sync job
         - Use enqueue() from sync_queue/operations.py
         - Build job data dict from scene data (same format as handle_task in Stash2Plex.py lines 885-911)
         - Deduplicate: load existing queue scene_ids via get_queued_scene_ids(), skip scenes already queued
         - Deduplicate: track scene_ids across gap types (a scene might appear in multiple gap lists)
      9. Return GapDetectionResult summary

    **GapDetectionResult dataclass:**
    - empty_metadata_count: int
    - stale_sync_count: int
    - missing_count: int
    - total_gaps: int
    - enqueued_count: int (how many were actually enqueued, after dedup)
    - skipped_already_queued: int
    - scenes_checked: int
    - errors: list[str] (non-fatal errors during detection, e.g., matcher failures for individual scenes)

    **Batch processing for large libraries (Claude's Discretion):**
    - Process Stash scenes in batches of 100 for the matching step to avoid memory issues
    - Log progress every 50 scenes processed
    - Use existing Stash plugin log functions (log_info, log_debug pattern)
    - Handle PlexNotFound exceptions from matcher gracefully (these are expected for missing items)
    - Handle PlexServerDown by stopping detection early and returning partial results with error

    **Plex metadata extraction helper: _extract_plex_metadata(plex_item) -> dict**
    - Extract from plexapi Video object: studio, actors (as list of names), genres (as list of names), summary, year/originallyAvailableAt
    - This converts Plex's data format into the same shape used by has_meaningful_metadata()

    **Job data builder helper: _build_job_data(stash_scene) -> dict**
    - Extract path, title, details, date, rating100, studio, performers, tags, poster_url, background_url
    - Same extraction logic as Stash2Plex.py handle_task lines 885-911
    - Return None if scene has no files (skip)

    Update reconciliation/__init__.py to export GapDetectionEngine and GapDetectionResult.

    Important implementation notes:
    - Do NOT trigger Plex library scans for missing items (per Claude's Discretion: rely on existing PlexNotFound-as-transient retry pattern)
    - Import PlexNotFound from plex.exceptions for handling matcher "no match" results
    - Use lazy imports for plex.client.PlexClient and plex.cache to match existing codebase patterns (avoid module-level imports that may fail if plexapi not installed)
  </action>
  <verify>
    ```bash
    cd /Users/trekkie/projects/PlexSync && python -c "from reconciliation.engine import GapDetectionEngine, GapDetectionResult; print('OK')"
    ```
  </verify>
  <done>GapDetectionEngine class exists with run() method, GapDetectionResult dataclass, and all helper methods</done>
</task>

<task type="auto">
  <name>Task 2: Engine tests with mocked Stash/Plex/Queue</name>
  <files>tests/reconciliation/test_engine.py</files>
  <action>
    Create comprehensive tests for GapDetectionEngine using mocked dependencies (unittest.mock, matching codebase convention).

    **Test fixtures needed:**
    - mock_stash: StashInterface mock with find_scenes() returning sample scenes (with updated_at, files, studio, performers, tags, details, date)
    - mock_config: Use existing mock_config fixture from conftest.py
    - mock_plex_client: PlexClient mock returning library sections with items
    - tmp_data_dir: temp directory for sync_timestamps.json and queue path
    - mock_queue: Use existing mock_queue fixture

    **Test cases:**

    1. test_run_detects_empty_metadata_gaps:
       - Setup: Stash scene with studio+performers, Plex item for same file with no metadata
       - Assert: result.empty_metadata_count == 1

    2. test_run_detects_stale_sync_gaps:
       - Setup: Stash scene with updated_at="2026-02-10T12:00:00Z", sync_timestamp for that scene at 2026-02-01 epoch
       - Assert: result.stale_sync_count == 1

    3. test_run_detects_missing_gaps:
       - Setup: Stash scene with no sync_timestamp entry, matcher raises PlexNotFound
       - Assert: result.missing_count == 1

    4. test_run_enqueues_gaps_when_queue_provided:
       - Setup: Multiple gap types detected, queue provided
       - Assert: enqueue called for each gap, result.enqueued_count matches

    5. test_run_deduplicates_against_existing_queue:
       - Setup: Scene already in queue (via get_queued_scene_ids mock), gap detected for same scene
       - Assert: enqueue NOT called for that scene, result.skipped_already_queued == 1

    6. test_run_deduplicates_across_gap_types:
       - Setup: Same scene appears as both empty_metadata and stale_sync gap
       - Assert: enqueue called only once for that scene

    7. test_run_scope_recent:
       - Setup: scope="recent"
       - Assert: stash.find_scenes called with updated_at filter for last 24 hours

    8. test_run_scope_all:
       - Setup: scope="all"
       - Assert: stash.find_scenes called without time filter

    9. test_run_handles_plex_server_down:
       - Setup: PlexClient.connect raises PlexServerDown
       - Assert: Returns partial result with error message, no crash

    10. test_run_detection_only_without_queue:
        - Setup: queue=None
        - Assert: Detection runs, result has counts, enqueued_count == 0

    11. test_lighter_pre_check_uses_sync_timestamps_first:
        - Setup: Scene has entry in sync_timestamps
        - Assert: Matcher is NOT called for that scene (pre-check short-circuits)

    12. test_job_data_builder_extracts_all_fields:
        - Test _build_job_data with full scene dict, verify all fields extracted correctly

    13. test_scenes_without_files_skipped:
        - Setup: Scene with empty files list
        - Assert: Scene skipped, no error

    Run full test suite to confirm no regressions:
    ```bash
    cd /Users/trekkie/projects/PlexSync && python -m pytest --cov --cov-fail-under=80 -v
    ```
  </action>
  <verify>
    ```bash
    cd /Users/trekkie/projects/PlexSync && python -m pytest tests/reconciliation/ -v
    cd /Users/trekkie/projects/PlexSync && python -m pytest --cov --cov-fail-under=80
    ```
  </verify>
  <done>All 13 engine tests pass, full test suite passes with 80% coverage, GapDetectionEngine correctly orchestrates detection and enqueue</done>
</task>

</tasks>

<verification>
```bash
# All reconciliation tests pass
cd /Users/trekkie/projects/PlexSync && python -m pytest tests/reconciliation/ -v

# Full test suite passes with coverage
cd /Users/trekkie/projects/PlexSync && python -m pytest --cov --cov-fail-under=80

# End-to-end import check
cd /Users/trekkie/projects/PlexSync && python -c "
from reconciliation.detector import GapDetector, GapResult, has_meaningful_metadata
from reconciliation.engine import GapDetectionEngine, GapDetectionResult
print(f'GapDetector methods: {[m for m in dir(GapDetector) if m.startswith(\"detect_\")]}')
print(f'GapDetectionResult fields: {[f.name for f in GapDetectionResult.__dataclass_fields__.values()]}')
print('All imports OK')
"
```
</verification>

<success_criteria>
- GapDetectionEngine.run() fetches Stash scenes and runs all three detectors
- Detected gaps are enqueued as standard sync jobs (same format as existing handle_task)
- Queue deduplication works: scenes already in queue are skipped
- Cross-gap-type deduplication works: same scene in multiple gap lists is enqueued once
- Lighter pre-check for missing detection: sync_timestamps checked before invoking matcher
- Scope parameter works: "all" fetches everything, "recent" filters to last 24 hours
- PlexServerDown is handled gracefully with partial results
- Detection-only mode works when queue=None
- All tests pass, 80% coverage maintained
- Engine is ready to be invoked by Phase 15's reconciliation task handler
</success_criteria>

<output>
After completion, create `.planning/phases/14-gap-detection-engine/14-02-SUMMARY.md`
</output>
